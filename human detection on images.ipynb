{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 d:\\ane folder\\human detection YOLO V8\\program\\trial.png: 480x640 1 bicycle, 1 car, 1 dog, 486.0ms\n",
      "Speed: 14.5ms preprocess, 486.0ms inference, 5.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict5\u001b[0m\n",
      "[16.0, 1.0, 2.0]\n",
      "Class: dog\n",
      "Class: bicycle\n",
      "Class: Car\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import cv2\n",
    "import torch.backends.cudnn as cudnn\n",
    "from PIL import Image\n",
    "import colorsys\n",
    "import numpy as np\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolov8n.pt\")  # load a pretrained model (recommended for training)\n",
    "\n",
    "results = model(\"trial.png\", save=True)\n",
    "\n",
    "\n",
    "\n",
    "class_names = ['person', 'bicycle', 'Car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
    "\n",
    "for result in results:\n",
    "    boxes = result.boxes  # Boxes object for bbox outputs\n",
    "    probs = result.probs  # Class probabilities for classification outputs\n",
    "    cls = boxes.cls.tolist()  # Convert tensor to list\n",
    "    xyxy = boxes.xyxy\n",
    "    xywh = boxes.xywh  # box with xywh format, (N, 4)\n",
    "    conf = boxes.conf\n",
    "    print(cls)\n",
    "    for class_index in cls:\n",
    "        class_name = class_names[int(class_index)]\n",
    "        print(\"Class:\", class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 d:\\ane folder\\human detection YOLO V8\\program\\test cases\\person.png: 416x640 1 person, 1 chair, 449.0ms\n",
      "Speed: 8.9ms preprocess, 449.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict2\u001b[0m\n",
      "[0.0, 56.0]\n",
      "Class: person\n",
      "Class: chair\n",
      "\n",
      "image 1/1 d:\\ane folder\\human detection YOLO V8\\program\\test cases\\Screenshot 2024-02-26 110135.png: 384x640 1 person, 3 bottles, 1 couch, 1 book, 372.8ms\n",
      "Speed: 12.4ms preprocess, 372.8ms inference, 12.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict2\u001b[0m\n",
      "[0.0, 39.0, 57.0, 39.0, 39.0, 73.0]\n",
      "Class: person\n",
      "Class: bottle\n",
      "Class: couch\n",
      "Class: bottle\n",
      "Class: bottle\n",
      "Class: book\n",
      "\n",
      "image 1/1 d:\\ane folder\\human detection YOLO V8\\program\\test cases\\Screenshot 2024-02-26 110146.png: 384x640 1 person, 1 potted plant, 357.0ms\n",
      "Speed: 8.0ms preprocess, 357.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict2\u001b[0m\n",
      "[0.0, 58.0]\n",
      "Class: person\n",
      "Class: potted plant\n",
      "\n",
      "image 1/1 d:\\ane folder\\human detection YOLO V8\\program\\test cases\\Screenshot 2024-02-26 110227.png: 448x640 1 person, 449.5ms\n",
      "Speed: 1.0ms preprocess, 449.5ms inference, 7.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict2\u001b[0m\n",
      "[0.0]\n",
      "Class: person\n",
      "\n",
      "image 1/1 d:\\ane folder\\human detection YOLO V8\\program\\test cases\\Screenshot 2024-02-26 110329.png: 352x640 6 persons, 1 bottle, 4 chairs, 2 dining tables, 1 tv, 2 laptops, 1 mouse, 1 cell phone, 394.8ms\n",
      "Speed: 18.6ms preprocess, 394.8ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict2\u001b[0m\n",
      "[63.0, 63.0, 0.0, 0.0, 0.0, 0.0, 62.0, 0.0, 0.0, 64.0, 56.0, 56.0, 56.0, 67.0, 60.0, 60.0, 39.0, 56.0]\n",
      "Class: laptop\n",
      "Class: laptop\n",
      "Class: person\n",
      "Class: person\n",
      "Class: person\n",
      "Class: person\n",
      "Class: tv\n",
      "Class: person\n",
      "Class: person\n",
      "Class: mouse\n",
      "Class: chair\n",
      "Class: chair\n",
      "Class: chair\n",
      "Class: cell phone\n",
      "Class: dining table\n",
      "Class: dining table\n",
      "Class: bottle\n",
      "Class: chair\n",
      "\n",
      "image 1/1 d:\\ane folder\\human detection YOLO V8\\program\\test cases\\Screenshot 2024-02-26 110403.png: 352x640 18 persons, 1 car, 1 stop sign, 313.2ms\n",
      "Speed: 8.0ms preprocess, 313.2ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict2\u001b[0m\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0]\n",
      "Class: person\n",
      "Class: person\n",
      "Class: person\n",
      "Class: person\n",
      "Class: person\n",
      "Class: person\n",
      "Class: person\n",
      "Class: person\n",
      "Class: person\n",
      "Class: person\n",
      "Class: person\n",
      "Class: person\n",
      "Class: person\n",
      "Class: car\n",
      "Class: person\n",
      "Class: person\n",
      "Class: stop sign\n",
      "Class: person\n",
      "Class: person\n",
      "Class: person\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolov8n.pt\")  # load a pretrained model (recommended for training)\n",
    "\n",
    "class_names = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
    "\n",
    "# Directory containing the images\n",
    "image_dir = \"test cases\"\n",
    "\n",
    "# Get a list of all image files in the directory\n",
    "image_files = [f for f in os.listdir(image_dir) if f.endswith((\".png\", \".jpg\", \".jpeg\"))]\n",
    "\n",
    "# Process only 6 images\n",
    "for image_file in image_files[:6]:\n",
    "    # Full path to the image\n",
    "    image_path = os.path.join(image_dir, image_file)\n",
    "    \n",
    "    # Perform object detection\n",
    "    results = model(image_path, save=True)\n",
    "    \n",
    "    # Process detection results\n",
    "    for result in results:\n",
    "        boxes = result.boxes  # Boxes object for bbox outputs\n",
    "        probs = result.probs  # Class probabilities for classification outputs\n",
    "        cls = boxes.cls.tolist()  # Convert tensor to list\n",
    "        xyxy = boxes.xyxy\n",
    "        xywh = boxes.xywh  # box with xywh format, (N, 4)\n",
    "        conf = boxes.conf\n",
    "        print(cls)\n",
    "        for class_index in cls:\n",
    "            class_name = class_names[int(class_index)]\n",
    "            print(\"Class:\", class_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
